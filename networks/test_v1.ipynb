{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cee953d-a887-4e3c-8232-4861e02d2aad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from networks.actor import Actor\n",
    "from networks.critic import Critic\n",
    "import torch\n",
    "\n",
    "# Actor: which takes a single input (obs + goal)\n",
    "# Critic: which takes two inputs (obs+goal, action)\n",
    "\n",
    "# Dummy environment parameters (matching Fetch environments)\n",
    "env_params = {\n",
    "    'obs_dim': 25,         # Size of observation vector\n",
    "    'goal_dim': 3,         # Size of goal vector\n",
    "    'action_dim': 4,       # Action space dimension\n",
    "    'act_limit': 1.0       # Maximum action magnitude\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "Actor Network\n",
    "--------------\n",
    "Input size:\n",
    "    Observation: 25\n",
    "    Goal: 3\n",
    "    Total input size: 28\n",
    "Output:\n",
    "    Action vector → shape [10, 4]\n",
    "\n",
    "[Input (28)] → FC1 (256) → ReLU\n",
    "             → FC2 (256) → ReLU\n",
    "             → FC3 (256) → ReLU\n",
    "             → Output (4) → tanh → scale by act_limit (1.0)\n",
    "###################################\n",
    "Critic Network\n",
    "-------------\n",
    "Input size:\n",
    "    Observation: 25\n",
    "    Goal: 3\n",
    "    Action: 4\n",
    "    Total input size: 28 + 4 = 32\n",
    "\n",
    "Architecture:\n",
    "[Input (32)] → FC1 (256) → ReLU\n",
    "             → FC2 (256) → ReLU\n",
    "             → FC3 (256) → ReLU\n",
    "             → Output (1) → Q-value\n",
    "Output:\n",
    "    Q-value → shape [10, 1] (1 scalar per sample)\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "| Item          | Shape      | Why                               |\n",
    "| ------------- | ---------- | --------------------------------- |\n",
    "| `obs`         | `[10, 25]` | 10 samples, 25 features each      |\n",
    "| `goal`        | `[10, 3]`  | 10 samples, 3 goal features each  |\n",
    "| `state_input` | `[10, 28]` | Concatenated obs + goal           |\n",
    "| `action`      | `[10, 4]`  | Actor outputs 4D action           |\n",
    "| `q_values`    | `[10, 1]`  | Critic outputs scalar Q per input |\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Network architecture\n",
    "hidden_layers = [256, 256]\n",
    "# Simulate a batch of inputs\n",
    "batch_size = 10\n",
    "\n",
    "# Create Actor and Critic instances\n",
    "actor = Actor(env_params, her=True, hidden_layers=hidden_layers)\n",
    "critic = Critic(env_params, her=True, hidden_layers=hidden_layers)\n",
    "\n",
    "\n",
    "# Random observation and goal vectors\n",
    "obs = torch.randn(batch_size, env_params['obs_dim'])   # → shape: [10, 25]\n",
    "goal = torch.randn(batch_size, env_params['goal_dim']) # → shape: [10, 3]\n",
    "\n",
    "# Concatenate observation and goal (since HER=True)\n",
    "state_input = torch.cat([obs, goal], dim=1)  # [10, 25] + [10, 3] → [10, 28]\n",
    "\n",
    "# Random actions to test critic\n",
    "action_input = torch.randn(batch_size, env_params['action_dim'])\n",
    "\n",
    "# Test Actor forward pass\n",
    "actions = actor(state_input) # One action vector of size 4 per input\n",
    "print(\"Actor output shape:\", actions.shape)  # Should be [10, 4]\n",
    "\n",
    "# Test Critic forward pass\n",
    "q_values = critic(state_input, actions)\n",
    "# state_input → [10, 28] and  actions → [10, 4] \n",
    "# It processes them and outputs a single scalar Q-value per input sample:  q_values = [10, 1]\n",
    "print(\"Critic output shape:\", q_values.shape)  # Should be [10, 1]\n",
    "\n",
    "# Inspect a sample output\n",
    "print(\"Sample Actor output:\\n\", actions[0])\n",
    "print(\"Sample Q-value:\\n\", q_values[0])\n",
    "\n",
    "print(\"Actor architecture:\\n\", actor)\n",
    "print(\"\\nCritic architecture:\\n\", critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32f83f14-2a42-4d8f-b5fe-5a51dfe686b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"=== Actor Architecture ===\")\n",
    "for i, layer in enumerate(actor.hidden_layers):\n",
    "    print(f\"Hidden Layer {i+1}: {layer}\")\n",
    "print(f\"Output Layer: {actor.action_out}\")\n",
    "\n",
    "print(\"\\n=== Critic Architecture ===\")\n",
    "for i, layer in enumerate(critic.hidden_layers):\n",
    "    print(f\"Hidden Layer {i+1}: {layer}\")\n",
    "print(f\"Output Layer: {critic.q_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa65bfbe-35d0-4bad-ae21-817088fd6058",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install torchsummary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "635c5c18-f881-4674-ab7a-60d637a3eb23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "\n",
    "# The -1 means: “This dimension can be any value — usually the batch size.”\n",
    "\n",
    "# Input size: 28 for actor, since obs (25) + goal (3)\n",
    "#summary(actor, input_size=(28,)) action_input\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "print(\"\\n--- Actor Summary ---\")\n",
    "summary(actor, input_size=(28,))\n",
    "\n",
    "# Wrap critic\n",
    "class CriticWrapper(nn.Module):\n",
    "    def __init__(self, critic):\n",
    "        super().__init__()\n",
    "        self.critic = critic\n",
    "\n",
    "    def forward(self, x):\n",
    "        state, action = x[:, :28], x[:, 28:]\n",
    "        return self.critic(state, action)\n",
    "\n",
    "wrapped_critic = CriticWrapper(critic)\n",
    "\n",
    "print(\"\\n--- Critic Summary ---\")\n",
    "summary(wrapped_critic, input_size=(32,))\n",
    "\n",
    "# Actor input: (28,)  → 25 obs + 3 goal\n",
    "# | Layer     | Output Shape | Parameters | Description                              |\n",
    "# | --------- | ------------ | ---------- | ---------------------------------------- |\n",
    "# | Linear-1  | `[-1, 256]`  | 7,424      | (28 + 1 bias) × 256                      |\n",
    "# | Linear-2  | `[-1, 256]`  | 65,792     | 256 × 256 + 256                          |\n",
    "# | Linear-3  | `[-1, 4]`    | 1,028      | 256 × 4 + 4                              |\n",
    "# | **Total** |              | **74,244** | ✓ This is correct for your 3-layer actor |\n",
    "\n",
    "#Critic input: (32,) → 25 obs + 3 goal + 4 action\n",
    "# | Layer        | Output Shape | Parameters | Description                                 |\n",
    "# | ------------ | ------------ | ---------- | ------------------------------------------- |\n",
    "# | Linear-1     | `[-1, 256]`  | 8,448      | (32 + 1 bias) × 256                         |\n",
    "# | Linear-2     | `[-1, 256]`  | 65,792     | 256 × 256 + 256                             |\n",
    "# | Linear-3     | `[-1, 1]`    | 257        | 256 × 1 + 1                                 |\n",
    "# | **Critic-4** | `[-1, 1]`    | 0          | The `Critic` module wrapper — has no params |\n",
    "# | **Total**    |              | **74,497** | ✓ Matches exactly what you designed         |\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "test_v1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
