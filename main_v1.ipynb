{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b4d65d8-111f-4b16-a553-f709582416f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d835d7c8-3599-4783-92ea-1ad7eb59ad17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install git+https://github.com/Farama-Foundation/Gymnasium-Robotics.git\n",
    "%pip uninstall -y mujoco-py\n",
    "%pip install mujoco\n",
    "%pip install gymnasium[robotics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "583864c8-52a4-425f-a327-63d28d99c00f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e60c748-f8f2-459b-881e-06062dfcb3ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip uninstall wandb\n",
    "%pip install --upgrade wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5c69dbf-e9e7-4aac-819a-712aa28cf190",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login(key=\"c61822f2a2c880a10a583de85a7b5bc378a3d9b4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f53f5834-c69b-4447-aa13-a90cb4cc153e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import gymnasium as gym\n",
    "import gymnasium_robotics\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "\n",
    "from networks.actor import Actor\n",
    "from networks.critic import Critic\n",
    "from replay_buffer.replay_buffer import ReplayBuffer\n",
    "from replay_buffer.her_buffer import HERBuffer\n",
    "from agents.ddpg import DDPGAgent\n",
    "from utils.logging import Logger\n",
    "from trainer.trainer import Trainer\n",
    "from utils.plotting import ResultsPlotter\n",
    "\n",
    "gym.register_envs(gymnasium_robotics)\n",
    "env = gym.make(\"FetchPush-v4\")\n",
    "\n",
    "obs_dim = env.observation_space[\"observation\"].shape[0]\n",
    "goal_dim = env.observation_space[\"desired_goal\"].shape[0]\n",
    "act_dim = env.action_space.shape[0]\n",
    "act_lim = np.array(env.action_space.high, dtype=np.float32)\n",
    "\n",
    "config = json.load(open(\"configs/test.json\"))\n",
    "\n",
    "env_params = {\n",
    "    \"obs_dim\": obs_dim,\n",
    "    \"goal_dim\": goal_dim,\n",
    "    \"action_dim\": act_dim,\n",
    "    \"act_limit\": act_lim\n",
    "}\n",
    "her = config.get(\"her\", True)\n",
    "hidden_layers = config.get(\"hidden_layers\", [256, 256])\n",
    "\n",
    "actor = Actor(env_params, her, hidden_layers)\n",
    "critic = Critic(env_params, her, hidden_layers)\n",
    "actor_target = deepcopy(actor)\n",
    "critic_target = deepcopy(critic)\n",
    "\n",
    "actor_optimizer = torch.optim.Adam(actor.parameters(), lr=config[\"lr_actor\"])\n",
    "critic_optimizer = torch.optim.Adam(critic.parameters(), lr=config[\"lr_critic\"])\n",
    "\n",
    "# replay_buffer = ReplayBuffer(obs_dim, act_dim, goal_dim, size=1_000_000)\n",
    "replay_buffer = HERBuffer(env.env.env.env.compute_reward, obs_dim, act_dim, goal_dim, size=1_000_000)\n",
    "\n",
    "\n",
    "agent = DDPGAgent(actor, critic, actor_target, critic_target, replay_buffer, config, actor_optimizer, critic_optimizer, act_lim)\n",
    "\n",
    "logger = Logger(log_dir=\"~/drl_project/logs_test_2delete/\", config=config)\n",
    "\n",
    "trainer = Trainer(agent, env, config, logger)\n",
    "\n",
    "# Run training step test\n",
    "#trainer.test_ddpg_training_step(agent, env, actor, critic, replay_buffer)\n",
    "\n",
    "trainer.train()\n",
    "plotter = ResultsPlotter(trainer)\n",
    "plotter.plot_all()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "main_v1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
